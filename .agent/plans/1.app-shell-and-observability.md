# Module 1: App Shell + Observability

> **Complexity:** :warning: **Medium** — Multiple moving parts (auth, chat, OpenAI, LangSmith), but each individually straightforward.

## Context

This is Module 1 of the Agentic RAG Masterclass. The goal is to deliver a working chat application with authentication, threaded conversations, streaming responses, and observability. It uses the OpenAI Responses API as a "black box" RAG solution — OpenAI manages threads, memory, and file search. The local database only stores thread references (not messages).

---

## Task 0: API Key Setup Guidance

Ensure the developer has all required credentials before any code is written.

**OpenAI API Key:**
1. Go to https://platform.openai.com/api-keys
2. Create a new secret key (name it e.g. "rag-masterclass")
3. Ensure billing is enabled (Responses API is paid)

**LangSmith API Key:**
1. Go to https://smith.langchain.com, sign up/log in
2. Settings → API Keys → Create API Key
3. Note the project name (create "rag-masterclass" or use "default")

**Supabase CLI:**
1. `brew install supabase/tap/supabase` (macOS)
2. Docker Desktop must be installed and running
3. Verify: `supabase --version`

**Validation:** Developer has OpenAI key, LangSmith key, Supabase CLI installed, Docker running.

---

## Task 1: Project Structure & Gitignore

Create the directory layout for frontend and backend.

```
frontend/src/{components/{ui,auth,chat,layout},hooks,lib,types,pages}
backend/app/{api/routes,core,models,services}
```

Update `.gitignore` with:
```
.env
backend/.env
frontend/.env
backend/venv/
node_modules/
```

Create `.env.example` at root with all required env vars (Supabase, OpenAI, LangSmith).

**Validation:** Directory tree matches expected layout.

---

## Task 2: Backend Scaffolding

**Goal:** Working Python FastAPI server with venv.

- Create `backend/requirements.txt`:
  - `fastapi`, `uvicorn[standard]`, `openai>=1.68.0`, `python-dotenv`, `pydantic`, `pydantic-settings`, `python-jose[cryptography]`, `httpx`, `sse-starlette`, `langsmith>=0.3.16`
- Create venv: `python3 -m venv venv && source venv/bin/activate && pip install -r requirements.txt`
- Create `backend/app/main.py` with FastAPI app, CORS (allow localhost:5173), health endpoint
- Create `backend/app/core/config.py` with Pydantic Settings loading from `.env`

**Validation:** `uvicorn app.main:app --reload --port 8000` → GET `/health` returns `{"status": "ok"}`

---

## Task 3: Frontend Scaffolding

**Goal:** Working React + Vite + Tailwind + shadcn/ui app using bun.

- `bun create vite frontend -- --template react-ts`
- Install Tailwind CSS v4: `bun add tailwindcss @tailwindcss/vite`
- Replace `src/index.css` with `@import "tailwindcss";`
- Configure path aliases (`@/*` → `./src/*`) in tsconfig + vite.config.ts
- Init shadcn/ui: `bunx --bun shadcn@latest init`
- Add components: `bunx --bun shadcn@latest add button input card scroll-area separator avatar dropdown-menu sheet dialog textarea`
- Install Supabase client: `bun add @supabase/supabase-js`
- Create `frontend/src/lib/supabase.ts` (client init from env vars)

**Validation:** `bun run dev` → page renders at localhost:5173, Tailwind classes work

---

## Task 4: Local Supabase Setup

**Goal:** Local Supabase running via CLI.

- `supabase init` at project root
- Edit `supabase/config.toml`: enable auth, set site_url to localhost:5173, disable email confirmations for local dev
- `supabase start` → outputs local URLs and keys
- Create `backend/.env` and `frontend/.env` with values from `supabase status`

**Validation:** `supabase status` shows all services running, Studio accessible at localhost:54323

---

## Task 5: Database Schema — Threads Table

**Goal:** Create threads table with RLS.

Create migration via `supabase migration new create_threads_table`:

```sql
create table public.threads (
  id uuid primary key default gen_random_uuid(),
  user_id uuid not null references auth.users(id) on delete cascade,
  title text not null default 'New Thread',
  openai_response_id text,  -- Latest response ID for previous_response_id chaining
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now()
);

-- RLS: users only see their own threads (select, insert, update, delete policies)
-- Auto-update trigger for updated_at
```

Apply with `supabase db reset`.

**Validation:** Table visible in Supabase Studio with RLS enabled.

---

## Task 6: Backend Auth — JWT Middleware

**Goal:** FastAPI dependency that validates Supabase JWTs.

- Create `backend/app/core/deps.py` — `get_current_user` dependency using `python-jose` to decode JWT with `audience="authenticated"`, extract user_id and email, return token for downstream Supabase calls
- Move health endpoint to `backend/app/api/routes/health.py` router

**Validation:** Unauthenticated requests return 403, invalid tokens return 401.

---

## Task 7: Frontend Auth — Sign In/Sign Up

**Goal:** Full auth flow with Supabase Auth.

- Create `frontend/src/hooks/useAuth.ts` — auth state management (getSession, onAuthStateChange, signUp, signIn, signOut)
- Create `frontend/src/lib/api.ts` — authenticated fetch helper (attaches Bearer token)
- Create `frontend/src/components/auth/AuthForm.tsx` — email/password form with sign-in/sign-up toggle, error display, loading states
- Create `frontend/src/pages/AuthPage.tsx` — centered auth form
- Create `frontend/src/components/layout/AppLayout.tsx` — header with user email + sign-out, sidebar placeholder, main content area
- Update `frontend/src/App.tsx` — conditional render: loading → auth page → app layout

**Validation:** Sign up creates user (visible in Studio), sign in works, sign out returns to auth form.

---

## Task 8: LangSmith Integration

**Goal:** Auto-trace all OpenAI calls.

- Create `backend/app/services/openai_client.py`:
  - Set LangSmith env vars (`LANGSMITH_TRACING`, `LANGSMITH_API_KEY`, `LANGSMITH_PROJECT`)
  - Create OpenAI client wrapped with `wrap_openai` from `langsmith.wrappers`
  - `wrap_openai` supports `client.responses.create` since langsmith 0.3.16

**Validation:** After making an OpenAI call, traces appear in LangSmith under the "rag-masterclass" project.

---

## Task 9: Backend — Thread CRUD Endpoints

**Goal:** API endpoints for thread management.

- Create `backend/app/core/database.py` — helper function for authenticated Supabase PostgREST requests (uses user's JWT so RLS is enforced)
- Create `backend/app/models/schemas.py` — Pydantic models: `ThreadCreate`, `ThreadResponse`, `MessageCreate`
- Create `backend/app/api/routes/threads.py`:
  - `GET /api/threads` — list user's threads (ordered by updated_at desc)
  - `POST /api/threads` — create new thread
  - `DELETE /api/threads/{id}` — delete thread
- Register router in main.py

**Validation:** curl with valid JWT can create, list, and delete threads.

---

## Task 10: Backend — Chat Endpoint + OpenAI Responses API

**Goal:** SSE streaming chat endpoint using OpenAI Responses API.

- Create `backend/app/services/chat.py`:
  - `send_message_streaming()` — calls `openai_client.responses.create()` with `stream=True`, `previous_response_id` for conversation threading, yields SSE events (`delta` for text chunks, `done` with response_id)
  - After stream completes, updates thread's `openai_response_id` in database
  - `generate_thread_title()` — on first message (previous_response_id is None), generates a short title via a second OpenAI call
- Create `backend/app/api/routes/chat.py`:
  - `POST /api/threads/{id}/messages` — fetches thread, gets previous_response_id, returns `EventSourceResponse`
- Model: `gpt-4o-mini` (cost-effective for development)

**Key design:** `previous_response_id` is the conversation threading mechanism. OpenAI reconstructs full context from the chain. We store only the latest response_id locally.

**Validation:** curl with `-N` flag streams SSE events. Second message in same thread shows conversation awareness. LangSmith shows traces.

---

## Task 11: Frontend — Thread Sidebar

**Goal:** Thread list with create/delete/select.

- Create `frontend/src/types/index.ts` — Thread and ChatMessage types
- Create `frontend/src/hooks/useThreads.ts` — fetch, create, delete threads via API
- Create `frontend/src/components/chat/ThreadSidebar.tsx`:
  - "New Thread" button at top
  - Thread list sorted by updated_at desc
  - Selected thread highlighted
  - Delete button on hover
  - Mobile: shadcn Sheet (drawer); Desktop: fixed left sidebar

**Validation:** Create, select, and delete threads in the UI.

---

## Task 12: Frontend — Chat Messages + Streaming

**Goal:** Message display with real-time SSE streaming.

- Create `frontend/src/hooks/useChat.ts`:
  - Maintains messages array
  - `sendMessage()` — adds user message, creates assistant placeholder, POSTs to chat endpoint, reads SSE stream via `fetch` + `ReadableStream` (not EventSource, which only supports GET), appends deltas to assistant message
  - Tracks `isStreaming` state
- Create `frontend/src/components/chat/MessageList.tsx` — user messages right-aligned, assistant left, auto-scroll, streaming indicator
- Create `frontend/src/components/chat/ChatInput.tsx` — textarea with Enter to send, Shift+Enter for newline, disabled while streaming
- Create `frontend/src/components/chat/ChatArea.tsx` — composes MessageList + ChatInput

**Validation:** Full chat flow — send message, watch streaming response, send follow-up showing context awareness.

---

## Task 13: Thread Title Auto-Update

After the first message in a thread, generate a title via a second OpenAI call and update the thread. Frontend re-fetches thread list to show updated title.

**Validation:** New thread title changes from "New Thread" to something descriptive after first exchange.

---

## Task 14: Polish & Error Handling

- Backend: global exception handler
- Frontend: error display for API failures, auth errors, stream failures
- Loading states: skeleton for thread list, spinner during streaming, disabled send button
- Responsive layout: sidebar collapses to drawer on mobile

**Validation:** Test error scenarios (backend down, invalid key, wrong password, mobile viewport).

---

## Task 15: Integration Testing

Full end-to-end verification:

1. Start all services: `supabase start`, backend (port 8000), frontend (port 5173)
2. Sign up → create thread → send message → watch streaming response → send follow-up → verify context
3. Verify thread title auto-updates
4. Create second thread → messages are independent
5. Check LangSmith: traces visible with input/output/latency/tokens
6. Sign up as second user → verify RLS (can't see first user's threads)
7. Check Supabase Studio: threads table has correct data

---

## Known Limitations (Intentional — addressed in Module 2)

1. **No local message persistence** — messages live on OpenAI's servers; switching threads loses displayed messages
2. **Locked to OpenAI** — Responses API is provider-specific
3. **No file upload** — file_search tool configured but no vector stores
4. **No ingestion interface** — built in Module 2
